{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo o Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_excel('Spam.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando o dataframe em 2, sendo 75% para o treino e 25% para o nosso programa avaliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>Hey cutie. How goes it? Here in WALES its kind...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>Meeting u is my work. . . Tel me when shall i ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>I'm fine. Hope you are good. Do take care.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2860</th>\n",
       "      <td>I am not at all happy with what you saying or ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>Its so common hearin How r u? Wat r u doing? H...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Email Class\n",
       "2155  Hey cutie. How goes it? Here in WALES its kind...   ham\n",
       "1067  Meeting u is my work. . . Tel me when shall i ...   ham\n",
       "4971         I'm fine. Hope you are good. Do take care.   ham\n",
       "2860  I am not at all happy with what you saying or ...   ham\n",
       "4920  Its so common hearin How r u? Wat r u doing? H...   ham"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSet, testSet = train_test_split(dados, test_size = 0.25)\n",
    "trainingSet.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando o dataframe de treino entre spam e ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset_spam = trainingSet.loc[trainingSet.Class=='spam']\n",
    "trainingset_ham = trainingSet.loc[trainingSet.Class=='ham']\n",
    "trainingSet_ham_final = trainingset_ham['Email']\n",
    "trainingSet_spam_final = trainingset_spam['Email']\n",
    "trainigSet_tudo = trainingSet['Email']\n",
    "x = testSet['Email']   #Dataframe para o teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcao para remover os caracteres especiais do dataframe de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpando_código (df):\n",
    "    new_df = df.values.tolist()\n",
    "    lista = []\n",
    "    for i in new_df:\n",
    "        lista.append(i.upper().split())\n",
    "    caracteres_especiais = ['!',',','?','.','#',' ','...','(',')','*','&','@','+','-','\"','<','>',\"'\"]\n",
    "    for e in range(0,len(lista)):\n",
    "        for i in lista[e]:\n",
    "            if i in caracteres_especiais:\n",
    "                lista[e].remove(i)\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcao para criar um dicionario da quantidade de vezes que uma mesma palavra aparece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicionario (lista):\n",
    "    dicionario = {}\n",
    "    for e in lista:\n",
    "        for i in e:\n",
    "            if i not in dicionario:\n",
    "                dicionario[i] = 1\n",
    "            else:\n",
    "                dicionario[i] +=1\n",
    "    return dicionario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando as funcoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario_ham = dicionario(limpando_código(trainingSet_ham_final))\n",
    "dicionario_spam = dicionario(limpando_código(trainingSet_spam_final))\n",
    "dicionario_tudo = dicionario(limpando_código(trainigSet_tudo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantidade de palavras em cada dicionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_palavras = len(dicionario_tudo)\n",
    "total_palavras_spam = len(dicionario_spam)\n",
    "total_palavras_ham = len(dicionario_ham)\n",
    "palavra_spam_total_geral = total_palavras + total_palavras_spam\n",
    "palavra_ham_total_geral = total_palavras + total_palavras_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario_test = dicionario(limpando_código(x)) #Limpando a base para teste\n",
    "lista_palavras = dicionario_test.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando a probabilidade de cada palavra estar relacionada a um email spam ou nao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_prob_spam = {}\n",
    "dic_prob_ham = {}\n",
    "for e in lista_palavras:\n",
    "    if e not in dicionario_ham:\n",
    "        prob_ham = 1/palavra_ham_total_geral\n",
    "        dic_prob_ham[e] = prob_ham\n",
    "    else:\n",
    "        prob_ham = (1+dicionario_ham[e])/palavra_ham_total_geral\n",
    "        dic_prob_ham[e] = prob_ham\n",
    "    if e not in dicionario_spam:\n",
    "        prob_spam = 1/palavra_spam_total_geral\n",
    "        dic_prob_spam[e] = prob_spam\n",
    "    else:\n",
    "        prob_spam = (1 + dicionario_spam[e])/palavra_spam_total_geral\n",
    "        dic_prob_spam[e] = prob_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo o teste na base de dados para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_final = limpando_código(testSet['Email'])\n",
    "classificacao = []\n",
    "for e in teste_final:\n",
    "    prob_ham = 1\n",
    "    prob_spam = 1\n",
    "    for i in e:\n",
    "        prob_spam *= dic_prob_spam[i]\n",
    "        prob_ham *= dic_prob_ham[i]\n",
    "    if prob_ham > prob_spam:\n",
    "        classificacao.append(0)\n",
    "    else:\n",
    "        classificacao.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_certo = testSet['Class']\n",
    "lista_final = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ham = 0 spam = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in lista_certo:\n",
    "    if e == 'ham':\n",
    "        lista_final.append(0)\n",
    "    else:\n",
    "        lista_final.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95908111988514\n",
      "0.040918880114860015\n"
     ]
    }
   ],
   "source": [
    "contador = 1\n",
    "certo = 0\n",
    "errado = 0 \n",
    "for contador in range(0,len(classificacao)):\n",
    "    if classificacao[contador] == lista_final[contador]:\n",
    "        certo+=1\n",
    "    else:\n",
    "        errado+=1\n",
    "    contador +=1\n",
    "porcentagem_certo = certo/len(classificacao)\n",
    "porcentagem_errado = errado/len(classificacao)\n",
    "print(porcentagem_certo)\n",
    "print(porcentagem_errado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando as porcentagens de falso positivos, positivos verdadeiros, falos negativos e negativos verdadeiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teste_separacoes (dados):\n",
    "    trainingSet, testSet = train_test_split(dados, test_size = 0.25)\n",
    "    trainingset_spam = trainingSet.loc[trainingSet.Class=='spam']\n",
    "    trainingset_ham = trainingSet.loc[trainingSet.Class=='ham']\n",
    "    trainingSet_ham_final = trainingset_ham['Email']\n",
    "    trainingSet_spam_final = trainingset_spam['Email']\n",
    "    trainigSet_tudo = trainingSet['Email']\n",
    "    teste = testSet['Email']\n",
    "    dicionario_test = dicionario(limpando_código(teste))\n",
    "    dicionario_ham = dicionario(limpando_código(trainingSet_ham_final))\n",
    "    dicionario_spam = dicionario(limpando_código(trainingSet_spam_final))\n",
    "    dicionario_tudo = dicionario(limpando_código(trainigSet_tudo))\n",
    "    lista_palavras = dicionario_test.keys()\n",
    "    total_palavras = len(dicionario_tudo)\n",
    "    total_palavras_spam = len(dicionario_spam)\n",
    "    total_palavras_ham = len(dicionario_ham)\n",
    "    palavra_spam_total_geral = total_palavras + total_palavras_spam\n",
    "    palavra_ham_total_geral = total_palavras + total_palavras_ham\n",
    "    dic_prob_spam = {}\n",
    "    dic_prob_ham = {}\n",
    "    for e in lista_palavras:\n",
    "        if e not in dicionario_ham:\n",
    "            prob_ham = 1/palavra_ham_total_geral\n",
    "            dic_prob_ham[e] = prob_ham\n",
    "        else:\n",
    "            prob_ham = (1+dicionario_ham[e])/palavra_ham_total_geral\n",
    "            dic_prob_ham[e] = prob_ham\n",
    "        if e not in dicionario_spam:\n",
    "            prob_spam = 1/palavra_spam_total_geral\n",
    "            dic_prob_spam[e] = prob_spam\n",
    "        else:\n",
    "            prob_spam = (1 + dicionario_spam[e])/palavra_spam_total_geral\n",
    "            dic_prob_spam[e] = prob_spam\n",
    "    teste_final = limpando_código(testSet['Email'])\n",
    "    classificacao = []\n",
    "    for e in teste_final:\n",
    "        prob_ham = 1\n",
    "        prob_spam = 1\n",
    "        for i in e:\n",
    "            prob_spam *= dic_prob_spam[i]\n",
    "            prob_ham *= dic_prob_ham[i]\n",
    "        if prob_ham > prob_spam:\n",
    "            classificacao.append(0)\n",
    "        else:\n",
    "            classificacao.append(1)\n",
    "    lista_certo = testSet['Class']\n",
    "    lista_final = []\n",
    "    for e in lista_certo:\n",
    "        if e == 'ham':\n",
    "            lista_final.append(0)\n",
    "        else:\n",
    "            lista_final.append(1)\n",
    "        contador = 1\n",
    "        falso_spam = 0\n",
    "        falso_ham = 0\n",
    "        spam_certo = 0\n",
    "        ham_certo = 0\n",
    "    for contador in range(0,len(classificacao)):\n",
    "        if classificacao[contador] == lista_final[contador]:\n",
    "            if classificacao[contador] == 1:\n",
    "                spam_certo +=1\n",
    "            else:\n",
    "                ham_certo+=1\n",
    "                \n",
    "        elif classificacao[contador] == 1:\n",
    "            falso_spam +=1\n",
    "        else:\n",
    "            falso_ham +=1\n",
    "            \n",
    "        contador +=1\n",
    "    porcentagem_falso_spam = falso_spam/len(classificacao)\n",
    "    porcentagem_falso_ham = falso_ham/len(classificacao)\n",
    "    porcentagem_spam_certo = spam_certo/len(classificacao)\n",
    "    porcentagem_ham_certo = ham_certo/len(classificacao)\n",
    "    return porcentagem_falso_spam, porcentagem_falso_ham, porcentagem_spam_certo, porcentagem_ham_certo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podemos dizer que nosso classificador e muito bom baseado na porcentagem obtida no item acima. Essas porcentagens nos dizem que ele tem uma chance muito maior de acertar nas previsoes feitas sobre os emails serem spam ou nao, do que falhar e acabar excluindo emails que eram relevantes e deixando irrelevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repitindo 10.000 vezes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_positivo_verdadeiro = []\n",
    "lista_negativo_verdadeiro = []\n",
    "for e in range(0,10000):\n",
    "    falso_spam,falso_ham,positivo_verdadeiro,negativo_verdadeiro = teste_separacoes(dados)\n",
    "    lista_positivo_verdadeiro.append(positivo_verdadeiro)\n",
    "    lista_negativo_verdadeiro.append(negativo_verdadeiro)\n",
    "    #df = pd.DataFrame({'resultados': [falso_spam,falso_ham,positivo_verdadeiro,negativo_verdadeiro],\n",
    "                  # },\n",
    "                  # index=['falso spam', 'falso ham', 'Positivo verdadeiro', 'negativo verdadeiro'])\n",
    "    # plot = df.plot.pie(y='resultados', figsize=(5, 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-90664673394d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlista_positivo_verdadeiro\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlista_negativo_verdadeiro\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfaixa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'´Positivos e negativos verdadeiros'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Frequência absoluta'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'renda (em mil reais)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "lista_positivo_verdadeiro[lista_negativo_verdadeiro].plot.hist(bins=faixa, title='´Positivos e negativos verdadeiros', figsize=(6,6), alpha=0.5)\n",
    "plt.ylabel('Frequência absoluta')\n",
    "plt.xlabel('renda (em mil reais)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um Classificador baseado na divisao da base de dados apenas uma vez tem probabilidades pequenas, mas existentes, de acabar sendo \"influenciado\" pela forma como a divisao foi feita. Como foi uma vez apenas, e possivel que as porcentagens de acertos e erros do nosso classificador sejam baseadas apenas naquela divisao, entao para diminuir ao maximo essa chance, refazemos 10000 vezes essa analise para que seja possivel ter uma ideia de como o classificador se comportaria em inumeras diversas divisoes da base de dados possiveis, dessa forma teremos ele o mais preparado possivel para qualquer tipo de email, ja que nao apenas treinamos ele baseado em inumeros emails, mas tambem fizemos esse treinamento 10000 vezes, tornando ele ainda mais preciso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
